{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50b9454a",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d8056",
   "metadata": {},
   "source": [
    "## Load enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e38c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20b8e13",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cafad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from opensearchpy import OpenSearch\n",
    "from dataclasses import dataclass\n",
    "from retry import retry\n",
    "from typing import Union, Literal, Optional, Generator\n",
    "import json\n",
    "from IPython.display import Markdown, clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f498fb",
   "metadata": {},
   "source": [
    "## List models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc71b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available models\")\n",
    "for i, model in enumerate(ollama.list()[\"models\"], 1):\n",
    "    print(f\"{i}: {model['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb31758",
   "metadata": {},
   "source": [
    "## Configable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cd4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL = \"llama3:8b-instruct-q6_K\"\n",
    "MODEL = \"qwen2:7b-instruct-q6_K\"\n",
    "# MODEL = \"phi:latest\"\n",
    "EMBEDDING_MODEL = \"all-minilm:latest\"\n",
    "OLLAMA_HOST = \"http://localhost:11434\"\n",
    "RETRY_COUNT = 5\n",
    "SELECT_TOP_RESULTS = 3\n",
    "INDEX_NAME = \"sfc_code_preprocess\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fc4aa",
   "metadata": {},
   "source": [
    "# OLLAMA client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca3ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_client: ollama.Client = ollama.Client(host=OLLAMA_HOST)\n",
    "\n",
    "def get_embedding(text: str, embedding_model: str) -> list[float]:\n",
    "    response = ollama_client.embeddings(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        prompt=text,\n",
    "    )\n",
    "    return response[\"embedding\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eb5ce1",
   "metadata": {},
   "source": [
    "# Opensearch client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d695f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENSEARCH_USERNAME = os.environ[\"OPENSEARCH_USERNAME\"]\n",
    "OPENSEARCH_PASSWORD = os.environ[\"OPENSEARCH_PASSWORD\"]\n",
    "OPENSEARCH_URL = os.environ[\"OPENSEARCH_URL\"]\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "\n",
    "def get_open_search(cluster_url: str, username: str, password: str):\n",
    "\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url], http_auth=(username, password), verify_certs=False\n",
    "    )\n",
    "    return client\n",
    "\n",
    "open_search_client: OpenSearch = get_open_search(\n",
    "    OPENSEARCH_URL, OPENSEARCH_USERNAME, OPENSEARCH_PASSWORD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ac751",
   "metadata": {},
   "source": [
    "# Get distinct topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_search(cluster_url: str, username: str, password: str):\n",
    "\n",
    "    client = OpenSearch(\n",
    "        hosts=[cluster_url], http_auth=(username, password), verify_certs=False\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "open_search_client: OpenSearch = get_open_search(\n",
    "    OPENSEARCH_URL, OPENSEARCH_USERNAME, OPENSEARCH_PASSWORD\n",
    ")\n",
    "\n",
    "\n",
    "results = open_search_client.search(\n",
    "    body={\n",
    "        \"size\": 0,\n",
    "        \"aggs\": {\n",
    "            \"distinct_sources\": {\n",
    "                \"composite\": {\n",
    "                    \"sources\": [\n",
    "                        {\"topic_title\": {\"terms\": {\"field\": \"topic_title.keyword\"}}},\n",
    "                        {\"file_url\": {\"terms\": {\"field\": \"file_url.keyword\"}}},\n",
    "                    ],\n",
    "                    \"size\": 10000,\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    },\n",
    "    index=INDEX_NAME,\n",
    ")\n",
    "\n",
    "buckets = results[\"aggregations\"][\"distinct_sources\"][\"buckets\"]\n",
    "buckets_topic_to_url = {\n",
    "    bucket[\"key\"][\"topic_title\"]: bucket[\"key\"][\"file_url\"] for bucket in buckets\n",
    "}\n",
    "topic_list = list(buckets_topic_to_url.keys())\n",
    "topic_choices: str = \"\\n\".join([f\"{i}. {topic}\" for i, topic in enumerate(topic_list, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12527601",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topic_choices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2cdca1",
   "metadata": {},
   "source": [
    "# Prompt handlers\n",
    "## Topic selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a7d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TopicSelector:\n",
    "    verbose: int = 0\n",
    "    header: str = (\n",
    "        \"Pick an index of document that you think that it can help answer the following question or pick 0 if you think they are not helpful. Please answer only as a number and do not include prologue, prefix or suffix\"\n",
    "    )\n",
    "    system_prompt: str = (\n",
    "        \"Pick a choice, please answer only a number and do not include prologue, prefix or suffix\"\n",
    "    )\n",
    "    topic_choices: tuple = tuple(topic_list)\n",
    "\n",
    "    def generate(self, prompt: str) -> int:\n",
    "        stream = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self.system_prompt,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        try:\n",
    "            response = \"\"\n",
    "            for chunk in stream:\n",
    "                response += chunk[\"message\"][\"content\"]\n",
    "\n",
    "        finally:\n",
    "            stream.close()\n",
    "        return response\n",
    "\n",
    "    def construct_prompt(self, question: str) -> str:\n",
    "        header = self.header\n",
    "        topic_choices = \"\\n\".join(\n",
    "            [f\"{i}. {topic}\" for i, topic in enumerate(self.topic_choices, 1)]\n",
    "        )\n",
    "        prompt = (\n",
    "            topic_selection_prompt\n",
    "        ) = f\"\"\"{header}\n",
    "\n",
    "# Available source:\n",
    "{topic_choices}\n",
    "\n",
    "# question:\n",
    "{question}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    @retry(tries=RETRY_COUNT, exceptions=ValueError)\n",
    "    def pick_a_choice(self, question) -> int:\n",
    "        prompt = self.construct_prompt(question)\n",
    "        result = int(self.generate(prompt))\n",
    "        assert result >= 0, \"Invalid generated result, Regenerating...\"\n",
    "        return int(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b082af8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopicSelector().pick_a_choice(\"I want to invest in real-estate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c24f8a",
   "metadata": {},
   "source": [
    "## Query builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query builder\n",
    "\n",
    "@dataclass\n",
    "class TextQueryBuilder:\n",
    "    verbose: int = 0\n",
    "    header: str = (\n",
    "        \"Based on the following question, what keywords should be queried in Opensearch\"\n",
    "    )\n",
    "    system_prompt: str = (\n",
    "        \"We have an Opensearch instant storing docuements about code of conduct.\"\n",
    "        \" You are a data engineer who expertise Opensearch query.\"\n",
    "        \" Please suggest text query based on user's question\"\n",
    "        \" return your answer only  and do not include prologue, prefix or suffix\"\n",
    "    )\n",
    "    topic_choices: tuple = tuple(topic_list)\n",
    "\n",
    "    def generate(self, prompt: str) -> int:\n",
    "        stream = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self.system_prompt,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        try:\n",
    "            response = \"\"\n",
    "            for chunk in stream:\n",
    "                response += chunk[\"message\"][\"content\"]\n",
    "        finally:\n",
    "            stream.close()\n",
    "        return response\n",
    "\n",
    "    def construct_prompt(self, question: str) -> str:\n",
    "        header = self.header\n",
    "        prompt = (\n",
    "            topic_selection_prompt\n",
    "        ) = f\"\"\"{header}\n",
    "\n",
    "# question:\n",
    "{question}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    @retry(tries=RETRY_COUNT)\n",
    "    def build(self, question) -> int:\n",
    "        prompt = self.construct_prompt(question)\n",
    "        result = self.generate(prompt)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def get_topic(question: str, verbose: int = 0) -> str:\n",
    "    topic_selected_index = topic_selector.pick_a_choice(question)\n",
    "    if topic_selected_index:\n",
    "        selected_topic = topic_selector.topic_choices[topic_selected_index - 1]\n",
    "        if verbose:\n",
    "            print(\n",
    "                f'THE QUESTION: \"{question}\" \\nSELECTED TOPIC: {topic_selected_index}. \"{selected_topic}\"\\nFROM {buckets_topic_to_url[selected_topic]}'\n",
    "            )\n",
    "        return selected_topic\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Provided sources are not seem related to the question\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327f9390",
   "metadata": {},
   "source": [
    "## Source summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82704537",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SourceSummarizer:\n",
    "    system_prompt: str = (\n",
    "    \"You are an expert in lawfirm who are assigned to consider whether a text data source \"\n",
    "    \"is useful to answer a user question or not. If yes, you will summarize the text \"\n",
    "    \"which corespond user's question for another expert to write answer the user , otherwise, do nothing. \"\n",
    "    '''You answer must be in JSON format with field:\n",
    "\"is_useful\": boolean determining whether the source is useful,\n",
    "\"summarize: string your summarization refering the part for the text or empty string if not useful\n",
    "    '''\n",
    "     \" return your answer only  and do not include prologue, prefix or suffix\"\n",
    "    )\n",
    "    def generate(self, prompt: str) -> int:\n",
    "        stream = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self.system_prompt,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=True,\n",
    "        )\n",
    "        try:\n",
    "            response = \"\"\n",
    "            for chunk in stream:\n",
    "                response += chunk[\"message\"][\"content\"]\n",
    "        finally:\n",
    "            stream.close()\n",
    "        return response\n",
    "    \n",
    "    def construct_prompt(self, question: str, text_source: str) -> str:\n",
    "        prompt = (\n",
    "            topic_selection_prompt\n",
    "        ) = f\"\"\"# Source:\n",
    "{text_source}\n",
    "# question:\n",
    "{question}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    @retry(tries=RETRY_COUNT, exceptions=json.JSONDecodeError)\n",
    "    def summarize(self, question: str, text_source: str):\n",
    "        prompt = self.construct_prompt(question, text_source)\n",
    "        result = self.generate(prompt)\n",
    "        return json.loads(result)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7658b3",
   "metadata": {},
   "source": [
    "## User interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class UserInteractor:\n",
    "    system_prompt: str = (\n",
    "        \"You are an humble expert in lawfirm, and your secretary already \"\n",
    "        \"prepared gists from the related document for \"\n",
    "        \"you to answer user's question. \"\n",
    "        \"Your duty is to answer the question \"\n",
    "        \"with confidence using the prepared \"\n",
    "        \"data source as a reference.\"\n",
    "        \"Please also add the reference of data source with URL to PDF file with page number \"\n",
    "        \"and encourage user to find out more information with it\"\n",
    "    )\n",
    "\n",
    "    def generate(self, prompt: str, stream: bool = False) -> str:\n",
    "        response = ollama.chat(\n",
    "            model=MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": self.system_prompt,\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            stream=stream,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def stream_text(\n",
    "        self,\n",
    "        generator: Generator[None, int, None],\n",
    "        additional_text: str = \"\",\n",
    "    ) -> Generator[None, int, None]:\n",
    "        for chunk in generator:\n",
    "            yield chunk[\"message\"][\"content\"]\n",
    "        yield from additional_text\n",
    "\n",
    "    def construct_prompt(\n",
    "        self, question: str, topic: str, contexts: list[str], source_url: str\n",
    "    ) -> str:\n",
    "        system_prompt = self.system_prompt.format()\n",
    "        context_prompt = \"- \" + \"\\n- \".join(contexts)\n",
    "\n",
    "        prompt = (\n",
    "            topic_selection_prompt\n",
    "        ) = f\"\"\"# question:\n",
    "{question}\n",
    "\n",
    "# Prepared data source:\n",
    "Document: {topic}\n",
    "{context_prompt}\n",
    "URL: {source_url}\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def answer(\n",
    "        self, question: str, topic: str, contexts: list[str], stream: bool = False\n",
    "    ) -> str:\n",
    "        source_url = buckets_topic_to_url[topic]\n",
    "        prompt = self.construct_prompt(question, topic, contexts, source_url)\n",
    "        response = self.generate(prompt, stream)\n",
    "        references = (\n",
    "            \"<br><br>**Reference**\\n\"\n",
    "            f\"> From: {source_url}\"\n",
    "            \"\\n* \"\n",
    "            + \"\\n* \".join(sorted(contexts, key=lambda x: int(x.rsplit(\" \", 1)[1])))\n",
    "        )\n",
    "        if not stream:\n",
    "            return response[\"message\"][\"content\"] + references\n",
    "\n",
    "        return self.stream_text(response, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ead7149",
   "metadata": {},
   "source": [
    "# Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_data_in_opensearch(\n",
    "    query: str,\n",
    "    search_method: Union[Literal[\"text\"], Literal[\"vector\"]],\n",
    "    topic_title: Optional[str],\n",
    ") -> dict:\n",
    "    \n",
    "    query_embedding = get_embedding(question, EMBEDDING_MODEL)\n",
    "\n",
    "    if search_method == \"vector\":\n",
    "        must = [{\"knn\": {\"embedding\": {\"vector\": query_embedding, \"k\": 5}}}]\n",
    "    elif search_method == \"text\":\n",
    "        must = [\n",
    "            {\n",
    "                \"match\": {\n",
    "                    \"text\": {\n",
    "                        \"query\": query,\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid search method\")\n",
    "    must += [\n",
    "        {\n",
    "            \"match\": {\n",
    "                \"topic_title\": {\n",
    "                    \"query\": topic_title,\n",
    "                },\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    query_body = {\n",
    "        \"query\": {\"bool\": {\"must\": must}},\n",
    "        \"_source\": False,\n",
    "        \"fields\": [\"id\", \"topic_title\", \"text\", \"file_url\", \"page_number\"],\n",
    "    }\n",
    "\n",
    "    results = open_search_client.search(body=query_body, index=INDEX_NAME)\n",
    "    return results\n",
    "\n",
    "\n",
    "def extract_search_results(search_results_raw: dict) -> list[str]:\n",
    "    return [\n",
    "        {\n",
    "            \"text\": result[\"fields\"][\"text\"][0],\n",
    "            \"topic\": result[\"fields\"][\"topic_title\"][0],\n",
    "            \"url\": result[\"fields\"][\"file_url\"][0],\n",
    "            \"page\": result[\"fields\"][\"page_number\"][0],\n",
    "        }\n",
    "        for result in search_results_raw[\"hits\"][\"hits\"][:SELECT_TOP_RESULTS]\n",
    "    ]\n",
    "\n",
    "\n",
    "def summarize_into_contexts(\n",
    "    source_summarizer: SourceSummarizer, search_results: list\n",
    ") -> list[str]:\n",
    "    contexts = []\n",
    "    for search_result in search_results:\n",
    "        summarized = source_summarizer.summarize(question, search_result[\"text\"])\n",
    "        topic = search_result[\"topic\"]\n",
    "        page = search_result[\"page\"]\n",
    "        if summarized[\"is_useful\"]:\n",
    "            summarized_text = summarized[\"summarize\"]\n",
    "            context = f'\"{summarized_text}\" - Page: {page}'\n",
    "            contexts.append(context)\n",
    "    return contexts\n",
    "\n",
    "\n",
    "def apologize(question: str, stream: bool = False) -> str:\n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Apologize the inqueriing user \"\n",
    "                    \"because we're don't have any information or duty to \"\n",
    "                    \"answer user's question due to you are built for lawfirm tasks. \"\n",
    "                    \"Remind the user that the topics available for you to answer are:\\n\"\n",
    "                    f\"{topic_choices}\"\n",
    "                    \"If possible, suggest any another helpful resource that \"\n",
    "                    \"he may find the answer.\"\n",
    "                ),\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f'Let the user know that you cannot the question \"{question}\" due to you don\\'t have information which user just enqueried.'},\n",
    "        ],\n",
    "        stream=stream,\n",
    "    )\n",
    "    if not stream:\n",
    "        return response[\"message\"][\"content\"]\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce92721f",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a788306",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_selector = TopicSelector()\n",
    "text_query_builder = TextQueryBuilder()\n",
    "source_summarizer = SourceSummarizer()\n",
    "user_interactor = UserInteractor()\n",
    "\n",
    "\n",
    "\n",
    "def answer_the_question(question: str, stream: bool = False, debug: bool = False) -> Union[Generator[str, None, None], str]:\n",
    "    \"\"\"Run the responding flow to answer user's question.\n",
    "    \n",
    "    Args:\n",
    "        question (str): User's question\n",
    "        stream (bool): Choose how to emitting the answer\n",
    "    Returns:\n",
    "        - Generator[str, None, None] if stream = True\n",
    "        - str if stream = False\n",
    "    \"\"\"\n",
    "    topic_selected_index = topic_selector.pick_a_choice(question)\n",
    "    if topic_selected_index < 1:\n",
    "        # We don't have information to answer the question.\n",
    "        return apologize(question, stream)\n",
    "    topic_title = topic_selector.topic_choices[topic_selected_index - 1]\n",
    "    if debug: print(f\"{topic_title=}\")\n",
    "    query_text = text_query_builder.build(question)\n",
    "    if debug: print(f\"{query_text=}\")\n",
    "    # Query\n",
    "    search_text_results_raw = search_data_in_opensearch(\n",
    "        query_text, search_method=\"text\", topic_title=topic_title\n",
    "    )\n",
    "    search_vector_results_raw = search_data_in_opensearch(\n",
    "        query_text, search_method=\"vector\", topic_title=topic_title\n",
    "    )\n",
    "    search_text_results = extract_search_results(search_text_results_raw)\n",
    "    search_vector_results = extract_search_results(search_vector_results_raw)\n",
    "\n",
    "    # Summerize useful resources\n",
    "    if debug: print(\"summarizing contexts\")\n",
    "    context_text_results = summarize_into_contexts(source_summarizer, search_text_results)\n",
    "    context_vector_results = summarize_into_contexts(\n",
    "        source_summarizer, search_vector_results\n",
    "    )\n",
    "    contexts = context_text_results + context_vector_results\n",
    "    if len(contexts) == 0:\n",
    "        # The retrieved resources are not useful. \n",
    "        return apologize(question, stream)\n",
    "    # Generate the answer\n",
    "    if debug: print(\"start generate the answer\")\n",
    "    answer = user_interactor.answer(question, topic=topic_title, contexts=contexts, stream=stream)\n",
    "    return answer\n",
    "\n",
    "\n",
    "def display_answer(answer: Union[Generator[str, None, None], str]):\n",
    "    if isinstance(answer, Generator):\n",
    "        cumulative_response = \"\"\n",
    "        for c in answer:\n",
    "            if isinstance(c, dict):\n",
    "                c = c[\"message\"][\"content\"]\n",
    "            print(c, end=\"\", flush=True)\n",
    "            cumulative_response += c\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(cumulative_response))\n",
    "    else:\n",
    "        display(Markdown(answer))\n",
    "        \n",
    "        \n",
    "# Display output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf1254",
   "metadata": {},
   "source": [
    "# Example\n",
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b84abf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "When investing in real estate, there are several critical details you should consider to ensure a successful and informed investment. Here’s an overview based on the provided document:\n",
       "\n",
       "1. **Transaction History**: Understanding past transactions can provide insights into how properties have been managed and valued over time.\n",
       "\n",
       "2. **Proposed Renovation Plans**: These plans are crucial for anticipating future improvements that could increase property value or attract better tenants, potentially increasing rental income.\n",
       "\n",
       "3. **Operating Data**:\n",
       "   - **Occupancy Rate**: High occupancy indicates stable cash flow.\n",
       "   - **Tenant Mix**: Diversification of tenant types can mitigate risks if a particular industry experiences downturns.\n",
       "   - **Lease Details**: Terms like duration, renewal options, and clauses for rent adjustments are important.\n",
       "\n",
       "4. **Rental Data**:\n",
       "   - **Average Rental per Square Foot**: This helps gauge the market value of the property relative to similar assets in the area.\n",
       "   - **Lease Expirations**: Managing lease terminations can influence cash flow and planning future investments or renovations.\n",
       "\n",
       "5. **Borrowing Policy**: The way a company finances its properties can affect its financial flexibility and stability, influencing dividends and overall investment performance.\n",
       "\n",
       "6. **Risk Mitigation Measures**: Understanding how the entity manages risks such as market fluctuations, property damage, or regulatory changes is crucial for long-term planning.\n",
       "\n",
       "7. **Dividend Policy**: Knowing how distributions are made from net income can help in planning returns on your investment.\n",
       "\n",
       "8. **Insurance Arrangements**: Adequate insurance coverage protects against various risks and ensures that potential losses do not impact the investment significantly.\n",
       "\n",
       "9. **Divestment Strategy**: Understanding the plan for selling assets can give insights into liquidity, which is essential when considering the timing of your investment exit.\n",
       "\n",
       "10. **Administrative Requirements & Governing Laws**:\n",
       "    - **Repossession and Tenant Protection**: These laws vary by region and impact your rights as an investor.\n",
       "    - **Exchange Rate Fluctuations**: International investments are sensitive to exchange rate changes, affecting property valuation.\n",
       "    - **Regulatory Frameworks for Overseas Properties**: Different jurisdictions have distinct rules regarding real estate investment.\n",
       "\n",
       "11. **Property Valuation Factors**:\n",
       "    - **Property Tax**: This can significantly impact the cost of ownership and cash flow.\n",
       "    - **Depreciation & Amortization**: Understanding these accounting methods affects reported income and asset values.\n",
       "    - **Qualified Minority-owned Property**: Check if investments comply with this requirement for specific benefits or regulations.\n",
       "\n",
       "12. **Investment Structure**:\n",
       "    - Ensure that your investment aligns with Hong Kong standards, especially regarding regulatory comparability when investing in overseas properties.\n",
       "    - Review the minimum requirements for the percentage of gross asset value invested in real estate and ensure full disclosure from the management company.\n",
       "\n",
       "13. **Details from Offering Document**: Look for specific information like the name, address, creation date of the scheme, investment policy, business plan, character of real estate investments, and competitive conditions to assess fit with your investment goals and risk tolerance.\n",
       "\n",
       "To explore these points further or get a detailed understanding, I recommend reviewing the full document available [here](https://www.sfc.hk/-/media/EN/files/COM/Reports-and-surveys/REIT-Code_Aug2022_en.pdf?rev=572cff969fc344fe8c375bcaab427f3b). This resource provides comprehensive guidance on real estate investment trusts (REITs) and should be a valuable tool in your research.<br><br>**Reference**\n",
       "> From: https://www.sfc.hk/-/media/EN/files/COM/Reports-and-surveys/REIT-Code_Aug2022_en.pdf?rev=572cff969fc344fe8c375bcaab427f3b\n",
       "* \"To invest in real estate, you need to know that assets must be disposed under normal market conditions, with transparent pricing. At least 75% of the gross asset value should be invested in real estate generating recurrent rental income consistently. The management company is required to publish the full investment portfolio of relevant real estate investments on their website monthly and include this information in annual and interim reports.\" - Page: 37\n",
       "* \"When considering investing in real estate, it's important to understand the details of property valuation including factors like property tax, depreciation, and amortization. Additionally, you should consider whether an investment in another listed real estate investment trust can be viewed as a Qualified Minority-owned Property. This depends on its structure, underlying investments, and regulatory regime comparability with Hong Kong standards. If the target's regulatory environment is similar to that of Hong Kong, such investments may not need to strictly adhere to all requirements set out by local codes.\" - Page: 43\n",
       "* \"This text details how a specific entity, through special purpose vehicles, distributes income from real estate investments according to local laws and regulations. It also mentions that distributions from minority-owned properties are part of the net income for distribution.\" - Page: 45\n",
       "* \"The text discusses administrative requirements, governing laws for repossession and tenant protection, exchange rate fluctuations impact on property valuation, regulatory frameworks for overseas properties, legal governance of conveyance in relevant overseas markets.\" - Page: 75\n",
       "* \"To invest in real estates, you should carefully review the following details listed in the offering document: \n",
       "- The name, registered address, and creation date of the scheme. \n",
       "- The investment policy and strategy of the scheme.\n",
       "- The business plan for property investments, including how monies raised will be used and any intended type of real estate investments (residential, commercial, industrial).\n",
       "- A discussion on the general character and competitive conditions of all real estate currently held or intended to be acquired by the scheme.\" - Page: 78\n",
       "* \"To invest in real estate, you should consider the transaction history, proposed renovation plans, operating data including occupancy rate and tenant mix, lease details, average rental per square foot, lease expirations, borrowing policy, risk mitigation measures, dividend policy, insurance arrangements, and divestment strategy.\" - Page: 79"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question: str = \"I want to invest in real estates. What detail should I know?\"\n",
    "answer = answer_the_question(question, stream=True, debug=True)\n",
    "display_answer(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a95459",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1f443f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To design a product about pooled retirement funds, it's essential to have a thorough understanding of the regulatory framework and key terms associated with these types of investment vehicles. Here are some suggestions based on your prepared data source:\n",
       "\n",
       "1. **Compliance**: Ensure that your product adheres to the Securities and Futures Ordinance (Cap. 571) in Hong Kong, which governs collective investment schemes like pooled retirement funds. This includes understanding the roles and responsibilities of 'principal brochure' or 'offering document', ensuring compliance with fair valuation, fee structures, investment strategy restrictions, and transfer/withdrawal policies.\n",
       "\n",
       "2. **Authorization Process**: Review the process mentioned on pages 6 and 45 for obtaining authorization to operate a pooled retirement fund under section 399(1) of the Securities and Futures Ordinance (Cap. 571). This will help you understand the steps required for legal registration and ongoing compliance.\n",
       "\n",
       "3. **Investment Objectives**: Clearly define your product's investment strategy, as outlined in Page 26. This includes specifying the percentage of total net asset value that must be invested according to indicated objectives or strategies. Ensure that these investments align with the regulatory requirements and cater to the risk profiles of potential investors.\n",
       "\n",
       "4. **Regulatory Compliance**: Familiarize yourself with terms such as 'regulated activity' (referred on Page 12), which can guide you in structuring your product offerings without inadvertently violating Hong Kong's financial regulations.\n",
       "\n",
       "5. **Product Offering Document**: Develop a comprehensive and clear principal brochure or offering document that includes all necessary information for investors, such as investment objectives, risk factors, fees, and any other details required by the regulatory body (as mentioned on Page 12).\n",
       "\n",
       "6. **Penalties and Compliance with Advertisements**: Be aware of potential offenses related to unauthorized advertisements as per sections covered in your reference document. Ensure that marketing materials are compliant with regulatory guidelines.\n",
       "\n",
       "7. **Product Code and Product Provider**: Understand how these terms apply within the context of pooled retirement funds (PRFs) as defined by the Hong Kong Securities and Futures Commission, which could influence branding and identification strategies for your product.\n",
       "\n",
       "For a more in-depth understanding and to ensure all aspects of your product design are thoroughly compliant with the law, I encourage you to download the full document provided below:\n",
       "URL: [https://www.sfc.hk/-/media/EN/assets/components/codes/files-current/web/codes/code-on-pooled-retirement-funds/code-on-pooled-retirement-funds.pdf?rev=9badf81950734ee08c799832be6ff92b](https://www.sfc.hk/-/media/EN/assets/components/codes/files-current/web/codes/code-on-pooled-retirement-funds/code-on-pooled-retirement-funds.pdf?rev=9badf81950734ee08c799832be6ff92b)\n",
       "\n",
       "This resource should provide a comprehensive guide to help you navigate the complexities of designing a pooled retirement fund product in Hong Kong, ensuring legal and regulatory compliance.<br><br>**Reference**\n",
       "> From: https://www.sfc.hk/-/media/EN/assets/components/codes/files-current/web/codes/code-on-pooled-retirement-funds/code-on-pooled-retirement-funds.pdf?rev=9badf81950734ee08c799832be6ff92b\n",
       "* \"This source provides guidance on the authorization of a collective investment scheme that is a pooled retirement fund under the Securities and Futures Ordinance (Cap. 571) in Hong Kong. It covers the powers of the Securities and Futures Commission to authorize, review, modify or withdraw such funds' authorizations and penalties for unauthorized advertisements related to these funds.\" - Page: 6\n",
       "* \"This text provides guidance on the authorization process of a collective investment scheme that is a pooled retirement fund under section 399(1) of the Securities and Futures Ordinance (Cap. 571). It also mentions potential offenses related to unauthorized advertisements for such funds.\" - Page: 6\n",
       "* \"The text defines key terms related to Pooled Retirement Funds (PRFs) in the context of Hong Kong's financial regulations. Terms such as 'principal brochure' or 'offering document', 'Product Code', and 'Product Provider' are explained, which could be helpful for designing a product about PRFs.\" - Page: 12\n",
       "* \"The text provides definitions related to pooled retirement funds in Hong Kong, including terms like 'pooled retirement fund' (PRF), 'principal brochure', and mentions codes and providers regulated by the Commission. It also refers to the meaning of 'regulated activity'. These definitions can provide a foundational understanding for designing a product about pooled retirement funds.\" - Page: 12\n",
       "* \"This text provides guidelines for named constituent and pooled investment funds regarding the percentage of total net asset value they must invest according to their indicated objectives or strategies. It also specifies restrictions on naming when investing in certain types of funds. These rules could be relevant for designing a product about pooled retirement funds, particularly concerning branding and investment strategy clarity.\" - Page: 26\n",
       "* \"The document outlines various aspects that are crucial for understanding and designing a pooled Retirement fund product, including fair valuation, fees, investment strategy and restrictions, termination conditions, and transfer or withdrawal policies. These points can be essential reference for creating a comprehensive and compliant retirement fund.\" - Page: 45"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question: str = \"I want to design product about pooled Retirement funds, any suggestion?\"\n",
    "answer = answer_the_question(question, stream=True, debug=True)\n",
    "display_answer(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05dfa3",
   "metadata": {},
   "source": [
    "## Example 3 (Unrelated question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d40d1040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm sorry, but I can't assist with that. It seems like there might be a misunderstanding as I'm an AI text-based model and currently unable to provide or look up specific recipes, cooking instructions, or answer questions about preparing food like fried chicken. However, you might find plenty of helpful resources online by searching on platforms such as YouTube, food blogs, or websites dedicated to recipes where many detailed guides on how to cook fried chicken are available.\n",
       "\n",
       "If you need help with another topic or have any other questions, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question: str = \"How to cook fried chicken?\"\n",
    "answer = answer_the_question(question, stream=True, debug=True)\n",
    "display_answer(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2f590f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
